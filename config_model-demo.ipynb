{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the Configurational Model\n",
    "# 19-2-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aims: To compare the network of messages which is created by the configuration\\\n",
    "# model with that actually observed in Facebook in December 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% IMPORT LIBRARIES NEEDED\n",
    "import networkx_extended as nx\n",
    "import empirical.Timeslice as ts   #For accessing network data\n",
    "import time  #For timing\n",
    "import numpy as np   #For plotting degree dist\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle #For loading data for 2009 timeslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% PROPERTIES OF NETWORK: METHODS FOR CALCULATING THEM\n",
    "#Largest Component Size\n",
    "def computeLCS(G):\n",
    "    '''Calculates order parameter on network G. In this case maximum component size'''\n",
    "    return len(max(nx.connected_components(G)))\n",
    "\n",
    "#Average Clustering Coefficient\n",
    "def computeClusteringCoefficients(Graph, isWeighted=False):\n",
    "    clustering_dicts = nx.algorithms.cluster.clustering(Graph)\n",
    "    avgClusteringCoefficient = nx.average_clustering(Graph)\n",
    "    return avgClusteringCoefficient, clustering_dicts\n",
    "\n",
    "def plot_distribution(d,name,n=1000):\n",
    "    '''Plots loglog frequency and cumulative distributions for a quantity\n",
    "    PARAMETERS\n",
    "    ---\n",
    "    d: dictionary\n",
    "        Dictionary of values to be histogrammed\n",
    "    name: string\n",
    "        Name of the quantity represented by the list of values\n",
    "    n: int\n",
    "        Number of bins\n",
    "    ''' \n",
    "#    log_max_degree = np.log10(max(d.values()))\n",
    "    n=len(d)\n",
    "    bin_edges = np.linspace(0,max(d.values()),n-1)\n",
    "    bin_edges = list(bin_edges)\n",
    "    bin_edges.insert(0,0.)\n",
    "    #print(bin_edges)\n",
    "    \n",
    "    #TODO: Loop through and create a dictionary {degree: frequency}\n",
    "    \n",
    "    plt.figure()\n",
    "    degree_dist,bins = np.histogram(list(d.values()),bins=bin_edges)\n",
    "    bin_centres = [sum(bin_edges[i:i+1]) for i in range(0,len(bin_edges)-1)]\n",
    "    plt.loglog(bin_centres,degree_dist,'+')\n",
    "    plt.xlim(1,1e4)\n",
    "    plt.grid()\n",
    "    plt.title('{} distribution'.format(name.capitalize()))\n",
    "    plt.xlabel('log({})'.format(name))\n",
    "    plt.ylabel('log(Frequency)')\n",
    "    plt.figure()\n",
    "    \n",
    "    degree_dist,degrees,patches = plt.hist(d.values(),bins=bin_edges,cumulative=True)\n",
    "    plt.title('Cumulative {} distribution'.format(name))\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Cumulative frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DEGREE DIST FOR DEC 2008 Timeslice---\n",
      "LOADING\n",
      "DONE LOADING\n",
      "PLOTTING\n",
      "DONE PLOTTING\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#%% DEGREE DIST FOR JAN 2009 Timeslice\n",
    "print(\"---DEGREE DIST FOR DEC 2008 Timeslice---\")\n",
    "print(\"LOADING\")\n",
    "degree_dict =dict( pickle.load(open('empirical/Results/2008_DEC_Weighted-degree_dict.pkl','rb')))\n",
    "print(\"DONE LOADING\")\n",
    "print(\"PLOTTING\")\n",
    "plot_distribution(dict(degree_dict),'degree')\n",
    "print(\"DONE PLOTTING\")\n",
    "print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL: USING DEGREE DIST FOR DEC 2008\n",
      "TOTAL EDGES IN NETWORK: 31198.0\n",
      "---MICROSTATE 1---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 20836\n",
      "Av. clustering coeff: 0.0002835217391234221\n",
      "----------------------\n",
      "---MICROSTATE 2---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0008409066894530099\n",
      "----------------------\n",
      "---MICROSTATE 3---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0013832914035443297\n",
      "----------------------\n",
      "---MICROSTATE 4---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0018981280541816082\n",
      "----------------------\n",
      "---MICROSTATE 5---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0023882747866938252\n",
      "----------------------\n",
      "---MICROSTATE 6---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0029265330863976423\n",
      "----------------------\n",
      "---MICROSTATE 7---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0035113909553958953\n",
      "----------------------\n",
      "---MICROSTATE 8---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.004047877547837548\n",
      "----------------------\n",
      "---MICROSTATE 9---\n",
      "RESULTS FOR MICROSTATE\n",
      "Largest cluster size: 23396\n",
      "Av. clustering coeff: 0.0046150747000361534\n",
      "----------------------\n",
      "---RESULTS FOR CONFIGURATION MODEL (9 ITERATIONS)---\n",
      "PEOPLE: 23396\n",
      "INTERACTIONS: 280098\n",
      "Largest cluster size: mean 23112, std: 8e+02\n",
      "Av. clustering coeff: mean: 0.00243, std: 0.0014\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#%% MODEL: USING DEGREE DIST FOR DEC 2008\n",
    "#Prints \"SELF-LOOP\" if a self-loop is found\n",
    "#Prints \"DOUBLE EDGE\" if an edge already exists between two users and increases weight on the edge\n",
    "\n",
    "import configuration_model\n",
    "print(\"\")\n",
    "print(\"MODEL: USING DEGREE DIST FOR DEC 2008\")\n",
    "\n",
    "#PARAMETERS\n",
    "no_of_iterations = 9\n",
    "\n",
    "lcs_list = list()\n",
    "ccs_list = list()\n",
    "\n",
    "print(\"TOTAL EDGES IN NETWORK: {}\".format(sum(degree_dict.values())/2))\n",
    "for i in range(no_of_iterations):\n",
    "    F = configuration_model.generateConfigNetwork(degree_dict)\n",
    "    print(\"---MICROSTATE {}---\".format(i+1))\n",
    "    if len(F.nodes()) < 100:\n",
    "        #DRAW NETWORK\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        nx.draw_networkx(F,pos=nx.circular_layout(F),ax=ax)\n",
    "        ax.set_xticks(list())\n",
    "        ax.set_yticks(list())\n",
    "        fig.show()\n",
    "    \n",
    "    lcs = computeLCS(F)\n",
    "    lcs_list.append(lcs)\n",
    "    ccs,ccs_dict = computeClusteringCoefficients(F,True)\n",
    "    ccs_list.append(ccs)\n",
    "    print(\"RESULTS FOR MICROSTATE\")\n",
    "    print('Largest cluster size: {}'.format(lcs))\n",
    "    print('Av. clustering coeff: {}'.format(ccs))\n",
    "    print(\"----------------------\")\n",
    "\n",
    "lcs_av = sum(lcs_list)/len(lcs_list)\n",
    "ccs_av = sum(ccs_list)/len(ccs_list)\n",
    "def std(l):\n",
    "    '''Returns standard deviation of a list l'''\n",
    "    SS = sum([i**2 for i in l])   #Sum of squares\n",
    "    N = len(l)\n",
    "    MSS = SS/N #Mean Sum of Squares\n",
    "    mean = sum(l)/N\n",
    "    return (MSS - mean**2)**.5\n",
    "\n",
    "lcs_std = std(lcs_list)\n",
    "ccs_std = std(ccs_list)\n",
    "print(\"---RESULTS FOR CONFIGURATION MODEL ({} ITERATIONS)---\".format(no_of_iterations))\n",
    "print('PEOPLE: {}'.format(len(F.nodes())))\n",
    "print('INTERACTIONS: {}'.format(len(F.edges())))\n",
    "print('Largest cluster size: mean {:.0f}, std: {:.2g}'.format(lcs_av,lcs_std))\n",
    "print('Av. clustering coeff: mean: {:.3g}, std: {:.2g}'.format(ccs_av,ccs_std))\n",
    "print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EMPIRICAL RESULTS FOR DEC 2008 TIMESLICE\n",
      "PEOPLE: 23396\n",
      "INTERACTIONS: 30964\n",
      "---RESULTS---\n",
      "Largest cluster size: mean 18885\n",
      "Av. clustering coeff: mean: 0.0417\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#%% EMPIRICAL RESULTS FOR DEC 2008\n",
    "print(\"\")\n",
    "print(\"EMPIRICAL RESULTS FOR DEC 2008 TIMESLICE\")\n",
    "loadedGraph = ts.loadGEXF(\"C:/Users/admin/Documents/Physics/year 3/WWWPhysics-PC/empirical/Data/WeightedNetwork/2008_DEC_WeightedGraph.gexf\")\n",
    "print('PEOPLE: {}'.format(len(loadedGraph.nodes())))\n",
    "print('INTERACTIONS: {}'.format(len(loadedGraph.edges())))\n",
    "lcs = computeLCS(loadedGraph)\n",
    "av_clustering, clustering_dict = computeClusteringCoefficients(loadedGraph,True) \n",
    "print(\"---RESULTS---\")\n",
    "print('Largest cluster size: mean {:.0f}'.format(lcs))\n",
    "print('Av. clustering coeff: mean: {:.3g}'.format(av_clustering))\n",
    "print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of self-edges: 4.77\n"
     ]
    }
   ],
   "source": [
    "#Self edges\n",
    "SS = sum([i*(i-1) for i in degree_dict.values()])\n",
    "expectedSE = SS/(sum(degree_dict.values()))\n",
    "print(\"Expected number of self-edges: {:.3g}\".format(expectedSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest cluster size was found to be similar to that observed in the actual interaction network giving a mean value for LCS using the degree distribution and nodes for the weighted timeslice of the network for December 2008. \n",
    "\n",
    "Clustering coefficients were found to be significantly smaller for the random network than the observed network. This is to be expected as the probability of someone with whom you have interacted posting or receiving a wall post on the wall of someone else whom you have interacted with is clearly far higher than random. This shows that there are clear correlations between the behaviour of users, and motivates us to use a network which uses additional information to model the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
